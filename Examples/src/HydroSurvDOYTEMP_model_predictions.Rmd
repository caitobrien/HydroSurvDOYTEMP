---
title: "R Notebook"
output: html_notebook
---
```{r packages}
library(ggplot2)
library(tidyverse)
library(brms)
library(beepr)
library(here)
library(tidybayes)
library(lme4)
library(broom)
library(modelr)
```


Current code below is setup to manually run each df of choice through to extract predictions. Next step would be to set as a function to clean-up code. 

## Data wrangling

```{r data_import}
#import saved subset file 
df<-read_csv(here("Examples/data/HydroSurvDOYTEMP_data_subset", "wild_spsu_chinook_data_subset.csv"))
df<-read_csv(here("Examples/data/HydroSurvDOYTEMP_data_subset", "hatchery_spsu_chinook_data_subset.csv"))
df<-read_csv(here("Examples/data/HydroSurvDOYTEMP_data_subset", "wild_steelhead_data_subset.csv"))
df<-read_csv(here("Examples/data/HydroSurvDOYTEMP_data_subset", "hatchery_steelhead_data_subset.csv"))

df<-read_csv(file.choose())
```



```{r data_subset,  eval=FALSE}

#---or use steps below
DATA <- read.csv(file = here("Examples/data", "dsynth_2021-03-02.spsu.subset.csv"), stringsAsFactors = FALSE, na.strings = c("", "NA"))

df<- DATA %>%
  # filter to include wild all run types, with a transport code released from LGR
  filter(
    t_rear_type == "W",
    !is.na(pass_type),
    str_detect(rel_site, "LGR")
  ) %>%
  # extract year/doy and filter to include 80 to 160 doy from 1993 to 2018
  mutate(
    year = lubridate::year(rel_time),
    doy = lubridate::yday(rel_time),
  ) %>%
  
  filter(
    between(year, 1993, 2018),
    between(doy, 80, 160)
  ) %>%
  # redesignate tranportation codes--double check on -S and -T at other locations 
  mutate(pass_type_T_R = case_when(
    str_detect(pass_type, "-S") & str_length(pass_type) == 5 ~ "remove",
    str_detect(pass_type, "-S") & str_length(pass_type) > 5 ~ "ROR",
    str_detect(pass_type, "-TB") ~ "ROR",
    str_detect(pass_type, "-TD") ~ "ROR",
    str_detect(pass_type, "ROR") ~ "ROR",
    str_detect(pass_type, "LWG-T") ~ "T",
    .default = "remove"
  )) %>%
  filter(pass_type_T_R != "remove") %>% 
  # # adding filters to match JG shared code for transport --- check this still stands
  # filter(if_else(pass_type_T_R == "ROR", 
  #                str_length(pass_type) %in% c(3, 7),
  #                str_detect(pass_type, "LWG-T")
  #                )
  #        ) %>%
  # add binary codes
  mutate(
    transport = if_else(pass_type_T_R == "T", 1, 0),
    alive = if_else(!is.na(adu_lgr_first), 1, 0),
    doyz = scale(doy, center = TRUE, scale = TRUE)
  ) 


#write.csv(df.WCH, row.names = F, here("Examples/data", "wild_spsu_chinook_data_subset.csv"))
#df.ChSSWRT <- read.csv(here("data", "ChSSWRT_data_subset.csv"))
```


```{r bind_temp_data, eval=FALSE}
#pulled from temp Rmarkdown
df.WCH<- df.WCH %>% 
  mutate(
    year = as.character(year),
    doy = as.character(doy)
  ) %>% 
  left_join(y= select(LGR.temp.data, LGR.temp, LGR.temp.apply, CY, DOY), by = c("year" = "CY", "doy" = "DOY")) %>% 
  mutate ( LGR.tempz = scale(LGR.temp, center = TRUE, scale = TRUE)
  ) %>% 
  select(!c( LGR.temp.apply, LGR.temp.applyz))
```


```{r data_aggregate}
#for binomial left hand trial 
df.agg <- df%>% 
  #calculate # of juveniles--used as total trials in binomial model
  group_by(year, doy, doyz, transport) %>% 
  mutate(doy = as.numeric(doy),
         n = n()) %>% 
  arrange(year, doy, doyz) %>% 
 # mutate(year = as.factor(year)) %>% 
  #set reponse as sum of alive per trials 
  summarize(alive = sum(alive),
            n = mean(n),
            mean.tempz = mean(LGR.tempz),
            mean.temp = mean(LGR.temp)) %>% 
  ungroup() %>% 
  #include sar based on pit tag returns of observed data-- binned by year, weekly doy (doy.bin), and transport (ROR v Transport)
  arrange(year, doy, doyz, transport) %>% 
  mutate(doy.bin = cut(doy, breaks = seq(90, 160, 10), include.lowest = TRUE)) %>% 
  group_by(year, transport, doy.bin) %>% 
  mutate(doy.median = round(median(doy), 0),
         sar.pit = alive/n) %>% 
         # sar.pit.se = sd(sar.pit)/sqrt(n),
         # sar.pit.lower = mean(sar.pit) - 1.96 * sar.pit.se,
         # sar.pit.upper = mean(sar.pit) + 1.96 * sar.pit.se) %>% 
  ungroup() %>% 
  mutate( date = parse_date_time(x = paste(year, doy), orders = "yj")) %>% 
  mutate(year = as.character(year),
         transport = as.character(transport))
```

# predict

```{r import_models}
mod_natural_chinook_doy <- readRDS(here::here("Examples/results", "mod_natural_chinook_doy.rds"))
mod_natural_chinook_temp<- readRDS(here::here("Examples/results", "mod_natural_chinook_temp.rds"))
mod_natural_steelhead_doy<- readRDS(here::here("Examples/results", "mod_natural_steelhead_doy.rds"))
mod_natural_steelhead_temp<- readRDS(here::here("Examples/results", "mod_natural_steelhead_temp.rds"))

mod_hatchery_chinook_doy<- readRDS(here::here("Examples/results", "mod_hatchery_chinook_doy.rds"))
mod_hatchery_chinook_temp<- readRDS(here::here("Examples/results", "mod_hatchery_chinook_temp.rds"))
mod_hatchery_steelhead_doy<- readRDS(here::here("Examples/results", "mod_hatchery_steelhead_doy.rds"))
mod_hatchery_steelhead_temp<- readRDS(here::here("Examples/results", "mod_hatchery_steelhead_temp.rds"))
  
```

```{r generate_newdata}
#####doy
scale.doy <- scale(as.numeric(df$doy))
scale.x.doy <- attr(scale.doy, "scaled:center")
scale.sd.doy <- attr(scale.doy, "scaled:scale")

scale.temp <- scale(as.numeric(df$LGR.temp))
scale.x.temp <- attr(scale.temp, "scaled:center")
scale.sd.temp <- attr(scale.temp, "scaled:scale")


newdata.doy <- expand_grid(
  doyz = ((90:160) - scale.x.doy) / scale.sd.doy,
  transport = c(0, 1),
  year = c(1993:2018),
  n = 1
  ) 

newdata.temp <- expand_grid(
  mean.tempz = seq_range(df$LGR.tempz, n = 71), #to match DOY 
  transport = c(0, 1),
  year = c(1993:2018),
  n = 1
  ) 

newdata<-bind_cols(newdata.doy,newdata.temp[,1])
```

```{r add_predictions_SAR_TI}
df.pred<-newdata %>% 
  tidybayes::add_linpred_draws(mod_natural_steelhead_doy, re_formula = NULL, allow_new_levels = TRUE, ndraws = 10, transform =TRUE) %>% 
  tidybayes::median_qi() %>% 
  rename(SAR = .linpred,
         SAR.lo = .lower,
         SAR.hi = .upper) %>% 
  group_by(year, doyz) %>% 
  mutate(transport = as.factor(transport),
         TI = if_else(transport == 1, (SAR[transport == 1] / SAR[transport == 0]), NA),
         TI.lo = ifelse(transport == 1, SAR.lo[transport == 1] / SAR.lo[transport == 0], NA),
         TI.hi = ifelse(transport == 1, SAR.hi[transport == 1] / SAR.hi[transport == 0], NA)) %>% 
  ungroup() %>% 
  mutate(doy = (doyz * scale.sd.doy) + scale.x.doy,
         date = parse_date_time(x = paste(year, doy), orders = "yj"),
         temp = (mean.tempz * scale.sd.temp) + scale.x.temp) 

# back calculate:  df.agg$doyz * attr(df.agg$doyz, 'scaled:scale') + attr(df.agg$doyz, 'scaled:center')
```

```{r append_obsdata_to_predictions}
#repeat code for each to get prediction
df.pred.w.stl.doy<-df.pred %>% 
  mutate(year = as.character(year),
         transport = as.character(transport)) %>% 
  left_join(select(df.agg, "transport", "year","doy", "sar.pit", "n"), by = c("transport", "year", "doy")) %>% 
  mutate( rear_type =   "Natural-origin", # "Hatchery-origin",#
          covariate =  "Day-of-year (DOY)" , # "Temperature (Â°C)",#
          species =  "Steelhead", # "Chinook", #
          transport = as.factor(transport),
          year = as.factor(year)) %>% 
  rename( n.obs = n.y)

```

# Export predictions

```{r combine_final_predictions}
all<-rbind(df.pred.w.ch.doy, df.pred.w.ch.temp,
           df.pred.h.ch.doy, df.pred.h.ch.temp,
           df.pred.w.stl.doy, df.pred.w.stl.temp,
           df.pred.h.stl.doy, df.pred.h.stl.temp)

write.csv(all, row.names = F, here("data", "df_mod_predict.csv"))


```


# Summary table

```{r summary_table_function}

#moved to fct_model_tables


#function to import models
import_models <- function(models_folder) {
  model_files <- list.files(models_folder, pattern = "\\.rds$", full.names = TRUE)
  model_list <- lapply(model_files, readRDS)
  names(model_list) <- gsub("\\.rds$", "", basename(model_files))
  return(model_list)
}

#define model folder path
models_folder<- here::here("data/models")

#import models from the designated folder path
model_list <- import_models(models_folder)
  

#function to generate and save tables from imported models
create_model_tables <- function(model_list, output_directory) {
  for (i in seq_along(model_list)) {
    #extract model name for file output
    model_name <- basename(names(model_list)[i])
    #extract coefficients and rename variables
    tbl <- as.data.frame(brms::fixef(model_list[[i]]))
    
    # Conditional row names based on model name
    if (grepl("doy", model_name, ignore.case = TRUE)) {
      row_names <- c("Intercept", "Day-of-years (DOY)", "DOY^2", "Transport", "DOY:Transport", "doyz2:transport")
    } else {
      row_names <- c("Intercept", "Temperature", "Temp^2", "Transport", "Temperature:Transport", "tempz2:transport")
    } 
    
    rownames(tbl) <- row_names
    
    # Extracting variables from the model name for the table header
    model_vars <- strsplit(model_name, "_")[[1]][2:4]  # Extracts species, rear_type, and covariate
    
    # Creating the table header
    header <-  paste("Table", i, "Covariates of model for", 
                     paste(paste0(tools::toTitleCase(model_vars[1]),"-origin"), tools::toTitleCase(model_vars[2]), collapse = " "),
                     "including the covariate",
                    ifelse(tolower(model_vars[3]) == "doy", "day-of-year (DOY)", "temperature (C)"))
    
    
    #create table
    table <- tbl %>%
      mutate_if(is.numeric, round, digits = 2) %>%
      knitr::kable("html", caption = paste0(header)) %>%
      kableExtra::kable_styling(c("striped", "hover"), full_width = TRUE) 

    
    #export to new file folder at html
    file_path <- file.path(output_directory, paste0("table_", model_name, ".html"))
    write_file(table, file_path)
  }
}


# Replace 'output_directory' with your desired output directory
output_directory <- here::here("inst/app/www")

# Create tables
create_model_tables(model_list, output_directory)




```



