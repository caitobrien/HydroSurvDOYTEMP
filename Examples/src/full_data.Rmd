---
title: "R Notebook"
output: html_notebook
---
```{r packages}
library(ggplot2)
library(tidyverse)
library(brms)
library(beepr)
library(here)
library(tidybayes)
library(lme4)
library(broom)
library(modelr)
```



#wild chinook

## Data wrangling

```{r data_import}
#import saved subset file 
df.WCH<-read_csv(here("Examples/data", "wild_spsu_chinook_data_subset.csv"))
```



```{r data_subset, eval=FALSE}

#---or use steps below
DATA <- read.csv(file = here("Examples/data", "dsynth_2021-03-02.spsu.subset.csv"), stringsAsFactors = FALSE, na.strings = c("", "NA"))

df.WCH <- DATA %>%
  # filter to include wild all run types, with a transport code released from LGR
  filter(
    t_rear_type == "W",
    !is.na(pass_type),
    str_detect(rel_site, "LGR")
  ) %>%
  # extract year/doy and filter to include 80 to 160 doy from 1993 to 2018
  mutate(
    year = lubridate::year(rel_time),
    doy = lubridate::yday(rel_time),
  ) %>%
  
  filter(
    between(year, 1993, 2018),
    between(doy, 80, 160)
  ) %>%
  # redesignate tranportation codes--double check on -S and -T at other locations 
  mutate(pass_type_T_R = case_when(
    str_detect(pass_type, "-S") & str_length(pass_type) == 5 ~ "remove",
    str_detect(pass_type, "-S") & str_length(pass_type) > 5 ~ "ROR",
    str_detect(pass_type, "-TB") ~ "ROR",
    str_detect(pass_type, "-TD") ~ "ROR",
    str_detect(pass_type, "ROR") ~ "ROR",
    str_detect(pass_type, "LWG-T") ~ "T",
    .default = "remove"
  )) %>%
  filter(pass_type_T_R != "remove") %>% 
  # # adding filters to match JG shared code for transport --- check this still stands
  # filter(if_else(pass_type_T_R == "ROR", 
  #                str_length(pass_type) %in% c(3, 7),
  #                str_detect(pass_type, "LWG-T")
  #                )
  #        ) %>%
  # add binary codes
  mutate(
    transport = if_else(pass_type_T_R == "T", 1, 0),
    alive = if_else(!is.na(adu_lgr_first), 1, 0),
    doyz = scale(doy, center = TRUE, scale = TRUE)
  ) 


#write.csv(df.WCH, row.names = F, here("Examples/data", "wild_spsu_chinook_data_subset.csv"))
#df.ChSSWRT <- read.csv(here("data", "ChSSWRT_data_subset.csv"))
```

Temperature data
```{r bind_temp_data}
#pulled from temp Rmarkdown
df.WCH<- df.WCH %>% 
  mutate(
    year = as.character(year),
    doy = as.character(doy)
  ) %>% 
  left_join(y= select(LGR.temp.data, LGR.temp, LGR.temp.apply, CY, DOY), by = c("year" = "CY", "doy" = "DOY")) %>% 
  mutate ( LGR.tempz = scale(LGR.temp, center = TRUE, scale = TRUE)
  ) %>% 
  select(!c(LGR.temp, LGR.temp.apply, LGR.temp.applyz))

```


```{r data_aggregate}
#for binomial left hand trial 
df.agg <- df.WCH %>% 
  #calculate # of juveniles--used as total trials in binomial model
  group_by(year, doy, doyz, transport) %>% 
  mutate(doy = as.numeric(doy),
         n = n()) %>% 
  arrange(year, doy, doyz) %>% 
 # mutate(year = as.factor(year)) %>% 
  #set reponse as sum of alive per trials 
  summarize(alive = sum(alive),
            n = mean(n),
            mean.tempz = mean(LGR.tempz)) %>% 
  ungroup() %>% 
  #include sar based on pit tag returns of observed data-- binned by year, weekly doy (doy.bin), and transport (ROR v Transport)
  arrange(year, doy, doyz, transport) %>% 
  mutate(doy.bin = cut(doy, breaks = seq(90, 160, 10), include.lowest = TRUE)) %>% 
  group_by(year, transport, doy.bin) %>% 
  mutate(doy.median = round(median(doy), 0),
         sar.pit = alive/n) %>% 
         # sar.pit.se = sd(sar.pit)/sqrt(n),
         # sar.pit.lower = mean(sar.pit) - 1.96 * sar.pit.se,
         # sar.pit.upper = mean(sar.pit) + 1.96 * sar.pit.se) %>% 
  ungroup() %>% 
  mutate( date = parse_date_time(x = paste(year, doy), orders = "yj"))
```

```{r import_models}
mod_wild_chinook_doy<- readRDS(here::here("Example/results", "mod_wild_chinook_doy.rds"))
mod_wild_chinook_temp<- readRDS(here::here("Example/results", "mod_wild_chinook_temp.rds"))
  
```

```{r predict}
#####doy
scale.DOY <- scale(as.numeric(df.WCH$doy))
scale.x <- attr(scale.DOY, "scaled:center")
scale.sd <- attr(scale.DOY, "scaled:scale")

##reassigns scale used for model to 90:160 for new dataset used in predictions. --could condense or pull scale from orig dataset
newdoyz <- ((90:160) - scale.x) / scale.sd 


#####


newdata.doy <- expand_grid(
  doyz = ((90:160) - attr(df.WCH$doyz, 'scaled:center')) / attr(df.WCH$doyz, 'scaled:scale'),
  transport = c(0, 1),
  year = c(1993:2018),
  n = 348  #270 was used for H/W CH, could change based on each? 348 = mean(df.agg.W$n)
  ) 


#####temp

```

