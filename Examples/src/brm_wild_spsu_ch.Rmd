---
title: "R Notebook"
output: html_notebook
---


```{r packages}
library(ggplot2)
library(tidyverse)
library(brms)
library(beepr)
library(here)
library(tidybayes)
library(lme4)
library(broom)
library(modelr)
```

# Data wrangling

```{r data_import}
#import saved subset file 
df.ChSSWRT<-read_csv(here("data", "ChSSWRT_data_subset.csv"))
```



```{r data_subset, eval=FALSE}

#---or use steps below
DATA <- read.csv(file = here("data", "dsynth_2021-03-02.spsu.subset.csv"), stringsAsFactors = FALSE, na.strings = c("", "NA"))

df.ChSSWRT <- DATA %>%
  # filter to include wild all run types, with a transport code released from LGR
  filter(
    t_rear_type == "W",
    !is.na(pass_type),
    str_detect(rel_site, "LGR")
  ) %>%
  # extract year/doy and filter to include 80 to 160 doy from 1993 to 2018
  mutate(
    year = lubridate::year(rel_time),
    doy = lubridate::yday(rel_time),
  ) %>%
  
  filter(
    between(year, 1993, 2018),
    between(doy, 80, 160)
  ) %>%
  # redesignate tranportation codes--double check on -S and -T at other locations 
  mutate(pass_type_T_R = case_when(
    str_detect(pass_type, "-S") & str_length(pass_type) == 5 ~ "remove",
    str_detect(pass_type, "-S") & str_length(pass_type) > 5 ~ "ROR",
    str_detect(pass_type, "-TB") ~ "ROR",
    str_detect(pass_type, "-TD") ~ "ROR",
    str_detect(pass_type, "ROR") ~ "ROR",
    str_detect(pass_type, "LWG-T") ~ "T",
    .default = "remove"
  )) %>%
  filter(pass_type_T_R != "remove") %>% 
  # # adding filters to match JG shared code for transport --- check this still stands
  # filter(if_else(pass_type_T_R == "ROR", 
  #                str_length(pass_type) %in% c(3, 7),
  #                str_detect(pass_type, "LWG-T")
  #                )
  #        ) %>%
  # add binary codes
  mutate(
    transport = if_else(pass_type_T_R == "T", 1, 0),
    alive = if_else(!is.na(adu_lgr_first), 1, 0),
    doyz = scale(doy, center = TRUE, scale = TRUE)
  ) 
# N=596462 same as JG filtered share code when run
#without JG Transport filter N = 598424 --not including -S or -T not == LWG-T

#write.csv(df.ChSSWRT, row.names = F, here("data", "ChSSWRT_data_subset.csv"))
#df.ChSSWRT <- read.csv(here("data", "ChSSWRT_data_subset.csv"))
```

```{r data_aggregate}
#for binomial left hand trial 
df.agg <- df.ChSSWRT %>% 
  #calculate # of juveniles--used as total trials in binomial model
  group_by(year, doy, doyz, transport) %>% 
  mutate(n = n()) %>% 
  arrange(year, doy, doyz) %>% 
 # mutate(year = as.factor(year)) %>% 
  #set reponse as sum of alive per trials 
  summarize(alive = sum(alive),
            n = mean(n)) %>% 
  ungroup() %>% 
  #include sar based on pit tag returns of observed data-- binned by year, weekly doy (doy.bin), and transport (ROR v Transport)
  arrange(year, doy, doyz, transport) %>% 
  mutate(doy.bin = cut(doy, breaks = seq(90, 160, 10), include.lowest = TRUE)) %>% 
  group_by(year, transport, doy.bin) %>% 
  mutate(doy.median = round(median(doy), 0),
         sar.pit = alive/n ) %>% 
         # sar.pit.se = sd(sar.pit)/sqrt(n),
         # sar.pit.lower = mean(sar.pit) - 1.96 * sar.pit.se,
         # sar.pit.upper = mean(sar.pit) + 1.96 * sar.pit.se) %>% 
  ungroup() %>% 
  mutate( date = parse_date_time(x = paste(year, doy), orders = "yj"))


#To backcalculate:
#df.agg$doyz * attr(df.agg$doyz, 'scaled:scale') + attr(df.agg$doyz, 'scaled:center')

```



explore data
```{r}
#look at raw data doy
df.agg %>%
  ggplot(aes(x = exp(doyz)/(1+exp(doyz)), y = alive/n, color=as.factor(transport))) +
  geom_point() +
  geom_smooth(method = "lm")

df.agg %>%
  ggplot(aes(x = doy/(1+doy), y = alive/n,color=as.factor(transport))) +
  geom_point() +
  geom_smooth(method = "lm")

df.agg %>%
  ggplot(aes(x = doy, y = alive/n,color=as.factor(transport))) +
  geom_bar(stat = "identity", position = "stack", fill= "transparent") +
  geom_smooth(method = "lm") + facet_wrap(~as.factor(transport))

df.ChSSWRT %>%
  group_by(year) %>%
  summarise(PROP = sum(alive)/n()) %>%
  plot()

df.agg %>% 
  ggplot(aes(x=doy, y=n, color=year))+
  geom_point()

df.ChSSWRT %>% 
  group_by(pass_type_T_R,pass_type) %>% 
  summarise(n())
  


```

# Model

- [plogis vs inv.logis:](https://stat.ethz.ch/R-manual/R-devel/library/boot/html/inv.logit.html) The inverse logit is defined by exp(x)/(1+exp(x)) 

## most current code
```{r mod_binomial}
#rm(mod.1)
mod.1.1 <- brm(alive | trials(n) ~ doyz + I(doyz^2) + transport + doyz:transport + I(doyz^2):transport + (1 + doyz + I(doyz^2) + transport | year), 
                   data = df.agg, 
                   family = binomial(link = "logit"), 
                   chains = 3,
                   cores = 3,
                   file = here("results", "mod.1.1")
                   )
summary(mod.1)
#mod.3 rerun with year as factor--no change
```


```{r mod_binomial_summary}
#plot estimates
#no transformation
stanplot(mod.1, 
         type = "areas",
         prob = 0.95)
#transformed
mcmc_plot(mod.1, 
         type = "areas",
         variable = "^b_", #only population effects
         prob = 0.95,
         transformations = "plogis", #transform
         regex = TRUE)

#extract estimates
#the categorical variables: transport
plogis(fixef(mod.1)[-c(2,3,5,6),-2])
#the continous variable: MSESC
plogis(fixef(mod.1)[-c(3:6),-2]*sd(pull(df.agg, doyz), na.rm = T))

###

pp_check(mod.1, ndraws = 100)

#https://bayesf22-notebook.classes.andrewheiss.com/bayes-rules/13-chapter.html

##### 

#logistic regression can also be used to model count or proportion data. Binary logistic regression assumes that the outcome variable comes from a bernoulli distribution (which is a special case of binomial distributions) where the number of trial n is 1 and thus the outcome variable can only be 1 or 0. In contrast, binomial logistic regression assumes that the number of the target events follows a binomial distribution with n trials and probability q. In this way, binomial logistic regression allows the outcome variable to take any non-negative integer value and thus is capable of handling count data.


#https://www.rensvandeschoot.com/tutorials/generalised-linear-models-with-brms/

#plot point estimates and CIs along with density of parameter estimates
mcmc_plot(brm_binomial_ChSSWRT, 
         type = "areas",
         variable = "^b_", #only population effects
         prob = 0.95,
         transformations = "exp", #transform
         regex = TRUE)

#extract parameter/coefficient estimates
#non-transformed results
fixef(brm_binomial_ChSSWRT)[,-2] 
#categorical variable: transport
exp(fixef(brm_binomial_ChSSWRT)[-c(2,3,5,6),-2]) 
#the continuous variable: doy; since DOY is a continuous variable, we can standardize the exponentiated DOY estimate (by multiplying the original estimate with the SD of the variable, and then then exponentiating the resulting number).
exp(fixef(brm_binomial_ChSSWRT)[-c(3:6),-2]*sd(pull(df.agg, doyz), na.rm = T))

#blue line = point estimate, shaded blue = 95% credibility intervals; plot shows narrow shape and non-zero crossing for main predictors. Also shows that later doy indicate lower survival (negative slope), and in comparison to transportation type, transporting versus in-river migration is more likely to survive. 
#Note that the interpretation of the parameter estimates is linked to the odds rather than probabilities. The definition of odds is: P(event occurring)/P(event not occurring). In this analysis, with other variables held constant,being transported increases the odds  of survival  by 98%??, whereas the interaction of Doy:transport  increases odds of survival to a lesser degree, 41%. DOY alone can lower the odds of survival by 26% (1-.74 = 26%). The baseline odds (intercept) of survival, mean DOY and in-river migration, lowers the odds of survival by 99.8% (1-.002). Notes
```


```{r p_mod_binomial}
#plot conditional effects w/o random/group-level effects
c_eff_cen <- conditional_effects(mod.1, prob = .95, method = "posterior_epred", re_formula = NA, spaghetti = F) 

#doy
plot(c_eff_cen, plot = FALSE)[[1]]
#transport
plot(c_eff_cen, plot = FALSE)[[2]]

#doy:transport
c_eff_intrxn_1 <- conditional_effects(mod.1, effects="doyz",conditions = data.frame(transport = 1), prob = .95, method = "posterior_epred", re_formula = NA) 

c_eff_intrxn_0 <- conditional_effects(mod.1, effects="doyz", conditions=data.frame(transport=0), prob = .95, method = "posterior_epred", re_formula = NA) 

plot(c_eff_intrxn_1, plot=FALSE)[[1]]#transport
plot(c_eff_intrxn_0, plot=FALSE)[[1]]#in-river



```


## previous code s
bernoulli
```{r mod_bernoulli, eval=FALSE}
mod.2 <- brm(alive ~ doyz + I(doyz^2) + transport + doyz:transport + I(doyz^2):transport + (1 + doyz + I(doyz^2) + transport | year), 
                   data = df.ChSSWRT, 
                   family = bernoulli(link = "logit"), 
                   chains = 3,
                   cores = 3,
                   file = here("results", "mod.2")
                   )
summary(mod.2)

```


# predict

adapting JG code
```{r mod_predict_SAR}
##create new dataframe with al doy, tran, and year options, set n trails =1

# salmon
W.scale.DOY.sal <- scale(df.ChSSWRT$doy) 
W.scale.x.sal <- attr(W.scale.DOY.sal, "scaled:center")
W.scale.sd.sal <- attr(W.scale.DOY.sal, "scaled:scale")

##reassigns scale used for model to 90:160 for new dataset used in predictions. --could condense or pull scale from orig dataset
newdoyz.w.sal <- ((90:160) - W.scale.x.sal) / W.scale.sd.sal 


#####


newdata <- expand_grid(
  doyz = newdoyz.w.sal,
  transport = c(0, 1),
  year = c(1993:2018),
  n = 270  #1 or mean?
  ) 

#####

#append other other predictors without expanding grid
newdata.full<-newdata %>% 
  mutate( "I(doyz^2)" = (doyz)^2,
          "doyz:transport" = doyz * transport,
          "I(doyz^2):transport " = (doyz)^2 * transport
)

#####
#options to use predict with diff newdata and re_formula options NA vs JG code grouping
#using newdata vs full with NA
pred.na<-predict(mod.1, newdata = newdata, re_formula = NA, allow_new_levels = TRUE)

#all predictors and using JG group level
pred.full<-predict(mod.1, newdata = newdata.full, re_formula = ~ (1 + DOYz + I(DOYz^2) + Transport | Year), allow_new_levels = TRUE) #transform = "plogis"

#all predictors (picked this one) --still NOT the same--predicts response alive per trial not in probability--attempt to calculate from predicted response? not much diff from tidybayes then and cleaner
pred.na.full<-predict(mod.1, newdata = newdata.full, re_formula = NA, allow_new_levels = TRUE, transform = "plogis", summary = TRUE) #transform = "plogis"

df.pred.brms<- data.frame(newdata.full, pred.na.full) %>% 
  rename(SAR = Estimate,
         SAR.se = Est.Error,
         SAR.lo = `Q2.5`,
         SAR.hi = `Q97.5`) %>% 
  mutate_at(c("SAR", "SAR.se", "SAR.lo", "SAR.hi"), plogis)
```

```{r data_T:I}
# T:I
## this code is essentially saying if T = 1, then use T =1 row to select SAR T=1 / SAR T=0. NA is left for T = 0,
## For CI, T= 1 and T=0 TIlo will equal the SARlo from T=1 / SARhi from T=0; and for TIhi, SARhi T=1/ SARlo T=0

df.pred.brms$TI <- NA
df.pred.brms$TI[df.pred.brms$transport == 1] <- df.pred.brms$TI[df.pred.brms$transport == 1] <- df.pred.brms$SAR[df.pred.brms$transport == 1] / df.pred.brms$SAR[df.pred.brms$transport == 0]
# T:I confidence interval
df.pred.brms$TI.lo[df.pred.brms$transport == 1] <- df.pred.brms$TI.lo[df.pred.brms$transport == 0] <- df.pred.brms$SAR.lo[df.pred.brms$transport == 1] / df.pred.brms$SAR.hi[df.pred.brms$transport == 0]
df.pred.brms$TI.hi[df.pred.brms$transport == 1] <- df.pred.brms$TI.hi[df.pred.brms$transport == 0] <- df.pred.brms$SAR.hi[df.pred.brms$transport == 1] / df.pred.brms$SAR.lo[df.pred.brms$transport == 0]

```

# explore tidybayes options predicted probabilities
updated each with re_formula = NULL to not include grouping-level effects? --matches JG code better
[](https://www.andrewheiss.com/blog/2022/09/26/guide-visualizing-types-posteriors/#generalized-linear-models-with-link-transformations)
[](https://www.andrewheiss.com/blog/2021/11/10/ame-bayes-re-guide/)
[](https://bayesf22-notebook.classes.andrewheiss.com/bayes-rules/13-chapter.html)
```{r mod_tidybayes_explore_SAR}
#####
#differences in linpred, epred, pred using tidybayes https://www.andrewheiss.com/blog/2022/09/26/guide-visualizing-types-posteriors/

df.logit<-df.agg %>% 
  add_linpred_draws(mod.1, re_formula = NA, allow_new_levels = TRUE, ndraws = 10,  value = "logitSAR")

df.explogit<-df.agg %>% 
  add_linpred_draws(mod.1, re_formula = NA, allow_new_levels = TRUE, ndraws = 10,  value = "explogitSAR", transform = TRUE) 

df.epred<-newdata.full %>% 
  add_epred_draws(mod.2, re_formula = NA, allow_new_levels = TRUE, ndraws = 10,  value = "epredSAR") 
 
df.pred<-df.agg %>%  
   add_predicted_draws(mod.1, re_formula = NA, allow_new_levels = TRUE, ndraws = 10,  value = "predSAR")

```


does a smoothing function need to be applied or rnorm() to match smooth predictions of others?
```{r mod_pred_wrangle_SAR}
df.pred<-newdata.full %>% 
  add_predicted_draws(mod.1, re_formula = NULL, allow_new_levels = TRUE, ndraws = 100) %>% 
  group_by(year, doyz, transport) %>% 
  mutate(n = n()) %>% 
  arrange(year, doyz) %>% 
  #set reponse as sum of alive per trials 
  summarize(alive = mean(.prediction),
            n = mean(n)) %>% 
  ungroup() %>% 
  mutate(SAR = alive/n) %>% 
  group_by(year, doyz, transport) %>% 
  median_qi(SAR) %>% 
  rename(SAR.lo = .lower,
         SAR.hi = .upper)

df.pred$TI <- NA
df.pred$TI[df.pred$transport == 1] <- df.pred$TI[df.pred$transport == 1] <- df.pred$SAR[df.pred$transport == 1] / df.pred$SAR[df.pred$transport == 0]
# T:I confidence interval
df.pred$TI.lo[df.pred$transport == 1] <- df.pred$TI.lo[df.pred$transport == 0] <- df.pred$SAR.lo[df.pred$transport == 1] / df.pred$SAR.hi[df.pred$transport == 0]
df.pred$TI.hi[df.pred$transport == 1] <- df.pred$TI.hi[df.pred$transport == 0] <- df.pred$SAR.hi[df.pred$transport == 1] / df.pred$SAR.lo[df.pred$transport == 0]
mod.1
```


```{r mod_pred_wrangle_SARP_manual}
df.pred.post<-mod.1 %>% 
  predicted_draws(newdata = newdata.full, re_formula = NULL, allow_new_levels = TRUE, ndraws = 100 )

get_variables(mod.1)
postpred_manual <- mod.1 |> 
  spread_draws(b_Intercept, b_doyz,b_IdoyzE2, b_transport, `b_doyz:transport`, `b_IdoyzE2:transport`, sigma) |> 
  mutate(mu = b_Intercept + 
           (b_flipper_length_mm * 
              penguins_avg_flipper$flipper_length_mm),  # This is posterior_linpred()
         y_new = rnorm(n(), mean = mu, sd = sigma))  # This is posterior_predict()

postpred_manual |> 
  select(.draw:y_new)
```


closest to JG code
```{r mod_linpred_wrangle_SAR}
df.linpred<-newdata.full %>% 
  add_linpred_draws(mod.1.1, re_formula = NULL, allow_new_levels = TRUE, ndraws = 10, transform =TRUE) %>% 
  median_qi() %>% 
  rename(SAR = .linpred,
         SAR.lo = .lower,
         SAR.hi = .upper) 
df.linpred <- df.linpred %>% 
  mutate(doy = (df.linpred$doyz * W.scale.sd.sal) + W.scale.x.sal,
         date = parse_date_time(x = paste(year, doy), orders = "yj") )

df.linpred$TI <- NA
df.linpred$TI[df.linpred$transport == 1] <- df.linpred$TI[df.linpred$transport == 1] <- df.linpred$SAR[df.linpred$transport == 1] / df.linpred$SAR[df.linpred$transport == 0]
# T:I confidence interval
df.linpred$TI.lo[df.linpred$transport == 1] <- df.linpred$TI.lo[df.linpred$transport == 0] <- df.linpred$SAR.lo[df.linpred$transport == 1] / df.linpred$SAR.lo[df.linpred$transport == 0] #JG code had SARlo1/SARhi0
df.linpred$TI.hi[df.linpred$transport == 1] <- df.linpred$TI.hi[df.linpred$transport == 0] <- df.linpred$SAR.hi[df.linpred$transport == 1] / df.linpred$SAR.hi[df.linpred$transport == 0]#JG code had SARhi1/SARlo0
```


```{r mod_linpred_csv}
df.pred.post<-df.linpred %>% 
  left_join(select(df.agg, "year", "doy", "transport", "sar.pit"), by = c("year", "doy", "transport")) %>% 
  mutate( rear_type = "W",
          covariate = "DOY",
          species = "Ch",
          transport = as.factor(transport),
          year = as.factor(year))

write.csv(df.pred.post, row.names = F, here("data", "ChSSWRT_mod_predict.csv"))

```

second closest
```{r mod_epred_wrangle_SAR}
df.epred<-newdata.full %>% 
  add_epred_draws(mod.1, re_formula = NULL, allow_new_levels = TRUE, ndraws = 10, transform = "plogis") %>% 
  median_qi() %>% 
  rename(SAR =.epred,
         SAR.lo = .lower,
         SAR.hi = .upper)

df.epred$TI <- NA
df.epred$TI[df.epred$transport == 1] <- df.epred$TI[df.epred$transport == 1] <- df.epred$SAR[df.epred$transport == 1] / df.epred$SAR[df.epred$transport == 0]
# T:I confidence interval
df.epred$TI.lo[df.epred$transport == 1] <- df.epred$TI.lo[df.epred$transport == 0] <- df.epred$SAR.lo[df.epred$transport == 1] / df.epred$SAR.hi[df.epred$transport == 0]
df.epred$TI.hi[df.epred$transport == 1] <- df.epred$TI.hi[df.epred$transport == 0] <- df.epred$SAR.hi[df.epred$transport == 1] / df.epred$SAR.lo[df.epred$transport == 0]


ggplot(df.epred, aes(x=doyz, y=SAR, color= as.factor(year)))+
  geom_point()

```





# figures

```{r themeset}

theme_predict <- theme_minimal() + 
  theme(axis.line.x = element_line(linewidth = 0.2),
        axis.ticks = element_line(linewidth = 0.2),
        axis.line.y = element_line(linewidth = 0.2),
        plot.title = element_text(size = 11),
        plot.subtitle = element_text(size = 10),
        text = element_text(size = 12),
        # legend.position = c(.95, .95),
        legend.justification = "right", #c("right", "top"),
        #legend.box.just = "right",
        #legend.margin = margin(6, 6, 6, 6),
        legend.key.size = unit(0.2, 'cm'),
        )

# theme_minimal()+
# theme(strip.text = element_blank(),
#      axis.line.x = element_line(linewidth = 0.2),
#     axis.ticks = element_line(linewidth = 0.2),
#    axis.line.y = element_line(linewidth = 0.2),
#   legend.position = "top",
#  legend.key.size = unit(0.2, 'cm'),
# legend.text = element_text(size=7),
# axis.text.x = element_text(angle=90, vjust=.5, hjust = 1),
# axis.title.x = element_text(margin = margin(t=8, r=0, b=0, l=0)),
# axis.title.y = element_text(margin = margin(t=0, r=8, b=0, l=0)),
# plot.title = element_text(size = 10, vjust = -7))


```


```{r}
plot_fx<- function(SAR_year){
  df.linpred %>% 
  left_join(df.agg %>% select(sar.pit,date, transport), by=c("date", "transport")) %>%
  filter(year == SAR_year) %>% 
  ggplot(aes( x= date, color = as.factor(transport))) +
  geom_point(aes(y =SAR, fill = as.factor(transport)))+
  geom_jitter(aes(y =sar.pit, shape = as.factor(transport)), alpha = .7)+
  geom_lineribbon( aes(y = SAR, ymin =SAR.lo, ymax = SAR.hi, fill = as.factor(transport)), alpha = .25) +
  labs( x = "Date", y = "SAR", color = NULL, 
        fill = NULL, shape = NULL, 
        title = "Predicted SAR versus observed SAR from PIT tag recoveries", 
        subtitle = paste("Year:",SAR_year)) +
  scale_color_manual(breaks = c(0, 1), 
                     values = c("steelblue4", "#b47747"),
                     labels = c("In-river, \npredicted with 95% CI", "Transported, \npredicted with 95% CI"))+
  scale_fill_manual(breaks = c(0, 1), 
                     values = c("steelblue4", "#b47747"),
                     labels = c("In-river, \npredicted with 95% CI", "Transported, \npredicted with 95% CI"))+
  scale_shape_manual(values = c(21,21),
                     breaks = c(0,1),
                     labels = c("In-river, observed", "Transported, observed")) +
  guides(shape = "legend") +
  theme_predict
  
}

plot_fx(2000)


#loop

# Create an empty list for all your plots
plot_list = list()

# Run the plotting function for all the species
for (i in unique(df.linpred$year)){
    plot_list[[i]] = plot_fx(i)
}

# Now you have a list of three plots - one for each species. 
# You can see the plots by changing the value within the square brackes from 1 to 3
plot_list[[2010]]


#without function aspect
df.linpred %>% 
  left_join(df.agg %>% select(sar.pit,date, transport), by=c("date", "transport")) %>%
  filter(year == 2000) %>% 
  ggplot(aes( x= date, color = as.factor(transport))) +
  geom_point(aes(y =SAR, fill = as.factor(transport)))+
  geom_jitter(aes(y =sar.pit, shape = as.factor(transport)), alpha = .7)+
  geom_lineribbon( aes(y = SAR, ymin =SAR.lo, ymax = SAR.hi, fill = as.factor(transport)), alpha = .25) +
  labs( x = "Date", y = "SAR", color = NULL, fill = NULL, shape = NULL)+
  scale_color_manual(breaks = c(0, 1), 
                     values = c("steelblue4", "#b47747"),
                     labels = c("In-river, \npredicted with 95% CI", "Transported, \npredicted with 95% CI"))+
  scale_fill_manual(breaks = c(0, 1), 
                     values = c("steelblue4", "#b47747"),
                     labels = c("In-river, \npredicted with 95% CI", "Transported, \npredicted with 95% CI"))+
  scale_shape_manual(values = c(21,21),
                     breaks = c(0,1),
                     labels = c("In-river, observed", "Transported, observed")) +
  guides(shape = "legend") +
  theme_predict


df.agg %>% 
  filter(year == 2001) %>% 
ggplot(aes( x= date, color = as.factor(transport))) +
  geom_point(aes(y =sar.pit))
 # geom_point(aes(y =sar.pit, fill=as.factor(transport)), shape = 21)+
  #geom_lineribbon( aes(y = SAR, ymin =SAR.lo, ymax = SAR.hi, fill = as.factor(transport)), alpha = .25) 

df.epred %>% 
  filter(year == 1994) %>% 
ggplot(
         aes( x= doyz, y =TI)) +
  geom_point()+
  geom_hline(yintercept = 1)+
  geom_lineribbon( aes(y = TI, ymin =TI.lo, ymax = TI.hi), alpha = .25)
```










# JG code
```{r data_JG_code, eval=FALSE}
# Passage-type designations salmon
# For the DART Transportation Filter, see method description here: https://www.cbr.washington.edu/dart/metadata/pit#transport
trans_type.sal <- unique(DATA$pass_type)[which(nchar(unique(DATA$pass_type)) == 5)] ##pulling out sting == 5 characters
lwg_trans_type <- c("LWG-T", "LWG-S") ##setting type option for transport
ror_type.sal <- c("ROR", unique(DATA$pass_type)[which(nchar(unique(DATA$pass_type)) == 7)]) ##pulling out sting == 7 characters AND "ROR" to assign ROR

# LGR site salmon
# More about the PIT Tag release sites, see https://www.cbr.washington.edu/dart/query/pit_relsites
LGR.site.sal <- grep("LGR", unique(DATA$rel_site), value = TRUE) ##grep searches for matches to LGR, pulling out unique rel sites and returns value not vector integer bc value=TRUE
# "LGRRBR" "LGRRRR" "LGR"    "LGRRTR" "LGRGWL" "LGRTRB" "LGRTAL" "LGROFL"  "LGRCOL" "LGRBPS" "LGRGAT" "LGRLDR"

# ROR W SS Chinook that have a release time and a length at LGR
##filtering to include wild ROR with t_run = 1,2,5 (data doesn't show any other options though) and has a release time
ChSSWR.DATA <- DATA[(DATA$pass_type %in% ror_type.sal) & DATA$t_run %in% c(1, 2, 5) & DATA$t_rear_type == "W" & (!is.na(DATA$rel_time)), ]
##of the filtered data, further subset by which have a release site with string "LGR" present
ChSSWR.DATA <- ChSSWR.DATA[which((ChSSWR.DATA$rel_site %in% LGR.site.sal) == TRUE), ] 

# W SS Chinook transported from LGR
##filter to include only lwg_trans_types c("LWG-T", "LWG-S") and all run types (1,2,5) and keep only wild with a release time
ChSSWT.DATA <- DATA[(DATA$pass_type %in% lwg_trans_type) == TRUE & DATA$t_run %in% c(1, 2, 5) & DATA$t_rear_type == "W" & (!is.na(DATA$rel_time)) == TRUE, ]
##of the filtered data, further subset by which have a release site with string "LGR" present
ChSSWT.DATA <- ChSSWT.DATA[which((ChSSWT.DATA$rel_site %in% LGR.site.sal) == TRUE), ]

# W SS Chinook ROR AND transported from LGR
ChSSWRT.DATA <- rbind(ChSSWR.DATA, ChSSWT.DATA) ##combine subsetted data of ROR and T

##create holder dataframe with LGRjuv = 1 for each row of ChSSWRT.DATA and 0 for LGRadt (adult)
ChSSWRT.DH.DATA <- data.frame(
  LGRjuv = rep(1, nrow(ChSSWRT.DATA)),
  LGRadt = 0,
  Year = NA,
  DOY = NA,
  Transport = 0
)

##change LGRadt to 1 if chSSWRT.DATA has a adult return timestamp
ChSSWRT.DH.DATA$LGRadt[!is.na(ChSSWRT.DATA$adu_lgr_first)] <- 1
##populate DH dataframe with year extracted from release time of ChSSWRT.DATA
ChSSWRT.DH.DATA$Year <- as.numeric(format(strptime(ChSSWRT.DATA$rel_time, "%Y-%m-%d %H:%M:%S"), "%Y"))
##populate DH dataframe with DOY extracted from release time of ChSSWRT.DATA
ChSSWRT.DH.DATA$DOY <- as.numeric(format(strptime(ChSSWRT.DATA$rel_time, "%Y-%m-%d %H:%M:%S"), "%j"))
##change transport from 0 to 1 if pass_type of ChSSWRT.DATA matches lwg_trans_types c("LWG-T", "LWG-S")
ChSSWRT.DH.DATA$Transport[ChSSWRT.DATA$pass_type %in% lwg_trans_type] <- 1

#--->skip to next chunk for brms data wrangling

# Dead Salmon
## created as a vector of values--using adjusted DH dataframe, if adu return = 0, then dead=1, if not then alive=0
LGR.dead.ind.sal <- ifelse(ChSSWRT.DH.DATA$LGRadt == 0, 1, 0)

# Alive.Dead matrix response salmon
##next create a dataframe pulling LGRadt from DH dataframe which is now representing alive and combine with newly created dead values. Convert into matrix format and append to DH dataframe
ChSSWRT.DH.DATA$AliveDead <- as.matrix(data.frame(alive = ChSSWRT.DH.DATA$LGRadt, dead = LGR.dead.ind.sal))

# Smolt migration season salmon
#filter to include DOY between 80 to 160 (spsu outmigration range)
ChSSWRT.DH.DATA <- ChSSWRT.DH.DATA[ChSSWRT.DH.DATA$DOY %in% (80:160), ]

# Smolt migration years 1993-2018
ChSSWRT.DH.DATA <- ChSSWRT.DH.DATA[ChSSWRT.DH.DATA$Year %in% 1993:2018, ]

# Normalize salmon data to mean of 0 and 1 SD 
##only need to do for DOY and add column for DOYz
ChSSWRT.DH.DATA$DOYz <- scale(ChSSWRT.DH.DATA$DOY)
```

predict code_JG
```{r predict_JG_code}
glmm7<-load(here("results", "glmm7.sal"))

# salmon
W.scale.DOY.sal <- scale(ChSSWRT.DH.DATA$DOY) 
W.scale.x.sal <- attr(W.scale.DOY.sal, "scaled:center")
W.scale.sd.sal <- attr(W.scale.DOY.sal, "scaled:scale")

## Check on this code--used to rescale back to DOY?
newdoyz.w.sal <- ((80:160) - W.scale.x.sal) / W.scale.sd.sal 

##create new data with newDOYz TRAN YEAR
W.newdata.sal <- expand_grid(
                              DOYz = newdoyz.w.sal,
                              Transport = c(0, 1),
                              Year = 1993:2018
                            )

#Add to new data for each remaining parameter
W.newdata.sal$"I(DOYz^2)" <- (W.newdata.sal$DOYz)^2
W.newdata.sal$"DOYz:Transport" <- W.newdata.sal$DOYz * W.newdata.sal$Transport
W.newdata.sal$"I(DOYz^2):Transport " <- W.newdata.sal$`I(DOYz^2)` * W.newdata.sal$Transport

##once new data is set, predict response- 
##why only including certain parameters in re.form? 
##dropped ~1 + DOYz + I(DOYz^2) + Transport + DOYz:Transport + I(DOYz^2):Transport from equation
W.pred.sal <- predict(glmm7.sal, W.newdata.sal, re.form = ~ (1 + DOYz + I(DOYz^2) + Transport | Year), allow.new.levels = TRUE)
hist(W.pred.sal)

##pulling certain columns from new data, and all predicted data plus appending a logistic distribution of probabilities from predictions (logitSAR and SAR)
WCh.pred.df <- data.frame(W.newdata.sal[, c(3, 2, 1, 4, 5, 6)], W.pred.sal, plogis(W.pred.sal))
names(WCh.pred.df) <- c("Year", "Transport", "DOYz", "I(DOYz^2)", "DOYz:Transport", "I(DOYz^2):Transport", "logitSAR", "SAR")

##extract logitSAR and SAR 

# matrix of new data for salmon
WCh.Xmat <- as.matrix(data.frame(1, WCh.pred.df[, c(3, 4, 2, 5, 6)]))
# variance-covariance matrix for model parameters
WCh.bvcov <- as.matrix(vcov(glmm7.sal))
# SE for predicted, based on matrix of new data
WCh.pred.se <- sqrt(diag(WCh.Xmat %*% WCh.bvcov %*% t(WCh.Xmat)))
WCh.pred.df$logitSAR.se <- WCh.pred.se
# Confidence interval
WCh.pred.df$SAR.lo <- plogis(WCh.pred.df$logitSAR - 1.96 * WCh.pred.df$logitSAR.se)
WCh.pred.df$SAR.hi <- plogis(WCh.pred.df$logitSAR + 1.96 * WCh.pred.df$logitSAR.se)
# factor for ggplot2
WCh.pred.df$Transport <- as.factor(WCh.pred.df$Transport)

##manually calc T:I from predicted SAR

# T:I
WCh.pred.df$TI <- NA
##why is it necessary to call code 2x? I don't think it is
WCh.pred.df$TI[WCh.pred.df$Transport == 1] <- WCh.pred.df$TI[WCh.pred.df$Transport == 1] <- WCh.pred.df$SAR[WCh.pred.df$Transport == 1] / WCh.pred.df$SAR[WCh.pred.df$Transport == 0]
# T:I confidence interval
WCh.pred.df$TI.lo[WCh.pred.df$Transport == 1] <- WCh.pred.df$TI.lo[WCh.pred.df$Transport == 0] <- WCh.pred.df$SAR.lo[WCh.pred.df$Transport == 1] / WCh.pred.df$SAR.hi[WCh.pred.df$Transport == 0]
WCh.pred.df$TI.hi[WCh.pred.df$Transport == 1] <- WCh.pred.df$TI.hi[WCh.pred.df$Transport == 0] <- WCh.pred.df$SAR.hi[WCh.pred.df$Transport == 1] / WCh.pred.df$SAR.lo[WCh.pred.df$Transport == 0]

## Add data points for weekly SARs from PIT tag data. Salmon
PIT.SAR.RT.sal <- ChSSWRT.DH.DATA[with(ChSSWRT.DH.DATA, order(Year, DOY)), ]
PIT.SAR.RT.sal$doybin <- cut(PIT.SAR.RT.sal$DOY, breaks = seq(80, 160, 10), include.lowest = TRUE)

# In-river. Salmon
PIT.SAR.ROR.sal <- PIT.SAR.RT.sal[PIT.SAR.RT.sal$Transport == 0, ]
# number of juvniles. Salmon
PIT.SAR.ROR.aggr.juv.sal <- aggregate(PIT.SAR.ROR.sal$LGRjuv, by = list(PIT.SAR.ROR.sal$Year, PIT.SAR.ROR.sal$doybin), FUN = sum)
# number of adults. Salmon
PIT.SAR.ROR.aggr.adt.sal <- aggregate(PIT.SAR.ROR.sal$LGRadt, by = list(PIT.SAR.ROR.sal$Year, PIT.SAR.ROR.sal$doybin), FUN = sum)
# number of juveniles and adults. Salmon
PIT.SAR.ROR.aggr.sal <- merge(PIT.SAR.ROR.aggr.juv.sal, PIT.SAR.ROR.aggr.adt.sal, by = c("Group.1", "Group.2"), all.x = TRUE)
names(PIT.SAR.ROR.aggr.sal) <- c("Year", "doybin", "N.juv.sal", "N.adt.sal")

# first day of the bin. Salmon
PIT.SAR.ROR.aggr.sal$doy.median <- ifelse(nchar(as.character(PIT.SAR.ROR.aggr.sal$doybin)) < 9,
  as.numeric(substr(PIT.SAR.ROR.aggr.sal$doybin, 2, 3)),
  as.numeric(substr(PIT.SAR.ROR.aggr.sal$doybin, 2, 4))
) + 5
PIT.SAR.ROR.aggr.sal$doyz <- (PIT.SAR.ROR.aggr.sal$doy.median - W.scale.x.sal) / W.scale.sd.sal

# observed SAR.Salmon
PIT.SAR.ROR.aggr.sal$pitsar <- PIT.SAR.ROR.aggr.sal$N.adt.sal / PIT.SAR.ROR.aggr.sal$N.juv.sal
# Transported. Salmon
PIT.SAR.Trans.sal <- PIT.SAR.RT.sal[PIT.SAR.RT.sal$Transport == 1, ]
# number of juvniles. Salmon
PIT.SAR.Trans.aggr.juv.sal <- aggregate(PIT.SAR.Trans.sal$LGRjuv, by = list(PIT.SAR.Trans.sal$Year, PIT.SAR.Trans.sal$doybin), FUN = sum)
# number of adults. Salmon
PIT.SAR.Trans.aggr.adt.sal <- aggregate(PIT.SAR.Trans.sal$LGRadt, by = list(PIT.SAR.Trans.sal$Year, PIT.SAR.Trans.sal$doybin), FUN = sum)
# number of juveniles and adults. Salmon
PIT.SAR.Trans.aggr.sal <- merge(PIT.SAR.Trans.aggr.juv.sal, PIT.SAR.Trans.aggr.adt.sal, by = c("Group.1", "Group.2"), all.x = TRUE)
names(PIT.SAR.Trans.aggr.sal) <- c("Year", "doybin", "N.juv.sal", "N.adt.sal")
# first day of the bin. Salmon
PIT.SAR.Trans.aggr.sal$doy.median <- ifelse(nchar(as.character(PIT.SAR.Trans.aggr.sal$doybin)) < 9,
  as.numeric(substr(PIT.SAR.Trans.aggr.sal$doybin, 2, 3)),
  as.numeric(substr(PIT.SAR.Trans.aggr.sal$doybin, 2, 4))
) + 5
PIT.SAR.Trans.aggr.sal$doyz <- (PIT.SAR.Trans.aggr.sal$doy.median - W.scale.x.sal) / W.scale.sd.sal

# observed SAR. Salmon
PIT.SAR.Trans.aggr.sal$pitsar <- PIT.SAR.Trans.aggr.sal$N.adt.sal / PIT.SAR.Trans.aggr.sal$N.juv.sal
# Change x-axis values to the ones that match actual dates
W.dum.at.sal <- (c(91, 100, 110, 121, 130, 140, 152, 161) - W.scale.x.sal) / W.scale.sd.sal

```

plot code_JG (greyed out)
```{r p_JG_code, eval=FALSE}
 #SAR plots. Salmon
 par(mfrow=c(3,5), mar=c(4,2,2,2), oma=c(3,3,3,3))
 for (i in 1993:2018) {
   plot(0,0, xlim=c(-2.5,2.65), ylim=c(0,0.05), type="n", xlab="Date", ylab="SAR", main=i, axes=FALSE)
   axis(1, at=W.dum.at, labels=c("Apr-1","Apr-10","Apr-20","May-1","May-10","May-20","Jun-1","Jun-10"))
   axis(2)

   polygon( c( WCh.pred.df$DOYz[WCh.pred.df$Year==i & WCh.pred.df$Transport==0],  x up
               rev(WCh.pred.df$DOYz[WCh.pred.df$Year==i & WCh.pred.df$Transport==0]) ),   x down
            c( plogis(WCh.pred.df$logitSAR[WCh.pred.df$Year==i & WCh.pred.df$Transport==0] + 1.96*WCh.pred.df$logitSAR.se[WCh.pred.df$Year==i & WCh.pred.df$Transport==0]),  y up
               rev(plogis(WCh.pred.df$logitSAR[WCh.pred.df$Year==i & WCh.pred.df$Transport==0] - 1.96*WCh.pred.df$logitSAR.se[WCh.pred.df$Year==i & WCh.pred.df$Transport==0]))),  y down
            col=transparent("blue",0.8), border=NA)

   polygon( c( WCh.pred.df$DOYz[WCh.pred.df$Year==i & WCh.pred.df$Transport==1],  x up
               rev(WCh.pred.df$DOYz[WCh.pred.df$Year==i & WCh.pred.df$Transport==1]) ),   x down
            c( plogis(WCh.pred.df$logitSAR[WCh.pred.df$Year==i & WCh.pred.df$Transport==1] + 1.96*WCh.pred.df$logitSAR.se[WCh.pred.df$Year==i & WCh.pred.df$Transport==1]),  y up
               rev(plogis(WCh.pred.df$logitSAR[WCh.pred.df$Year==i & WCh.pred.df$Transport==1] - 1.96*WCh.pred.df$logitSAR.se[WCh.pred.df$Year==i & WCh.pred.df$Transport==1]))),  y down
            col=transparent("black",0.8), border=NA)

   if (i %in% unique(PIT.SAR.Trans.aggr$Year)) {

     for (ii in 1:length(PIT.SAR.ROR.aggr$doyz[PIT.SAR.ROR.aggr$Year==i])) {
       points(PIT.SAR.ROR.aggr$doyz[PIT.SAR.ROR.aggr$Year==i][ii],
              PIT.SAR.ROR.aggr$pitsar[PIT.SAR.ROR.aggr$Year==i][ii],
              pch=16, col=transparent("blue",0), cex=log(PIT.SAR.ROR.aggr$N.juv[PIT.SAR.ROR.aggr$Year==i][ii])/10)
     }

     for (ii in length(1:PIT.SAR.Trans.aggr$doyz[PIT.SAR.Trans.aggr$Year==i])) {
       points(PIT.SAR.Trans.aggr$doyz[PIT.SAR.Trans.aggr$Year==i][ii],
              PIT.SAR.Trans.aggr$pitsar[PIT.SAR.Trans.aggr$Year==i][ii],
              pch=15, col=transparent("gray50",0), cex=log(PIT.SAR.Trans.aggr$N.juv[PIT.SAR.Trans.aggr$Year==i][ii])/10)
     }
   }

   lines(WCh.pred.df$DOYz[WCh.pred.df$Year==i & WCh.pred.df$Transport==0], WCh.pred.df$SAR[WCh.pred.df$Year==i & WCh.pred.df$Transport==0], col="blue", lwd=1.5)

   lines(WCh.pred.df$DOYz[WCh.pred.df$Year==i & WCh.pred.df$Transport==1], WCh.pred.df$SAR[WCh.pred.df$Year==i & WCh.pred.df$Transport==1], col="gray50", lty=1.5)

 }

  T:I plots
 for (i in 1993:2018) {
   plot(0,0, xlim=c(-2.5,2.65), ylim=c(0,6), type="n", xlab="Date", ylab="SAR", main=i, axes=FALSE)
   axis(1, at=W.dum.at, labels=c("Apr-1","Apr-10","Apr-20","May-1","May-10","May-20","Jun-1","Jun-10"))
   axis(2)
   abline(h=1,lty=2)
   lines(WCh.pred.df$DOYz[WCh.pred.df$Year==i & WCh.pred.df$Transport==0],
         WCh.pred.df$SAR[WCh.pred.df$Year==i & WCh.pred.df$Transport==1]/WCh.pred.df$SAR[WCh.pred.df$Year==i & WCh.pred.df$Transport==0],
         type="l")
 }
```

